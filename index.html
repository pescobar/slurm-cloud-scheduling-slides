<!DOCTYPE html>
<html>
  <head>
    <title>Slurm cloud scheduling on OpenStack</title>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
    <link rel="stylesheet" type="text/css" href="css/common.css">
  </head>
  <body>
  <textarea id="source">

class: center, middle

# Slurm cloud scheduling on OpenStack

Or how to dynamically start and stop slurm compute nodes on OpenStack

Pablo Escobar Lopez

sciCORE

---

# sciCOREMed

- Secure IT environment for sensitive data analysis

- Based on OpenStack private cloud

- Projects are isolated from each other for improved security (OpenStack multitenancy)

- Hardware resources for projects:

    - 16 compute nodes 

    - 848 cpus (with multithreading)

    - ~ 4TB ram
    
    - 4 GPUs

---

# What problem we had?

.center[![:scale 60%](img/multitenancy-try1.png)]

.small[
- When deploying "static" slurm clusters, compute nodes allocated in a tenant are not accessible from other tenants.

- Moving compute nodes between tenants required sysadmin intervention.

- **PROBLEM:**We had idle nodes in a tenant while other tenants were lacking resources.

]

---

# Possible solutions

## option 1

 - Deploy static slurm in a shared tenant where every user from every project has access

   - This is similar to how the regular sciCORE cluster works. Users work on a shared cluster.

   - Access control is done using file system permissions.

   - It's less secure.

   - Not using the flexibility provided by cloud environments.

---

# Possible solutions

## option 2

 - Buy more hardware so every tenant has a static slurm cluster

   - Perfect solution. It's just expensive and less efficient (hardware is idle)

   .center[![:scale 60%](img/multitenancy-try1.png)]
---

# Possible solutions

## Our Solution

   - Slurm has the ability to support a cluster that grows and shrinks on demand.

   - This Slurm feature is called "cloud scheduling" or "elastic computing" 
     [https://slurm.schedmd.com/elastic_computing.html](https://slurm.schedmd.com/elastic_computing.html)

   - "BUT" there is no native support for OpenStack. We had to implement it.

---

# How Slurm's cloud scheduling works

   .center[![:scale 50%](img/multitenancy-try1.png)]

.small[
- Each project/tenant only has slurm master and slurm submit hosts running

- Users can see compute nodes available but those nodes are in fact not running (no resources allocated)

- When a user submits a job slurm master contacts the OpenStack API to boot the compute node on demand.

- When the job finishes the compute node is stopped/deleted and resources released so they can be used by other tenants.
]

---
# How Slurm's cloud scheduling works

.center[
![:scale 100%](img/sinfo.png)
]

.center[
![:scale 100%](img/srun-bash.png)
]
---

# Our implementation

   - We extended our slurm ansible role to add support for cloud scheduling. https://github.com/scicore-unibas-ch/ansible-role-slurm/pull/4

   - Main development were these two python scripts used by slurm master to start/stop compute nodes using the OpenStack API:
       - https://github.com/scicore-unibas-ch/ansible-role-slurm/blob/master/templates/slurm_resume_openstack.py.j2
       - https://github.com/scicore-unibas-ch/ansible-role-slurm/blob/master/templates/slurm_suspend_openstack.py.j2

   - We also use slurm configless mode. https://slurm.schedmd.com/configless_slurm.html

---

# Our implementation. Some technical details

- We create an OpenStack image to be used by the compute nodes. This image includes the required config (LDAP client config for user accounts, shared file systems mounts, slurm config...etc)

- We create an OpenStack "Application Credential" to be used by the slurm master to authenticate against the OpenStack API. Access to API is restricted to slurm master.

- When a user submits a slurm job the slurm master contact the API and boots the required compute node(s).

---

# Our implementation. Some technical details

- When the compute node(s) boots it contacts the slurm master to get the latest slurm config (Slurm configless)

- When the job finishes the slurm master contact the OpenStack API to shutdown the compute node and release the resources (idle timeout is configurable)
   
- Feel free to contact me if you want more technical details. I should not go into geek mode in this presentation :_(

---


# Security challenges

sciCOREMed is a secure environment but monitoring security events when compute nodes are dynamically started/stopped is not trivial.

We use a host-based intrusion detection system (HIDS) which is not easy to handle in a dynamic environment.

We are working to improve this part.

---

# Bonus track 1/3

   - Slurm cloud scheduling can be integrated with JupyterLab and Open OnDemand. This allows users to boot Jupyter and Rstudio instances on demand.

.center[
![:scale 80%](img/guacamole-1.png)
]

---

# Bonus track 2/3

.center[
![:scale 90%](img/guacamole-2.png)
]

---

# Bonus track 3/3

.center[
![:scale 90%](img/guacamole-3.png)
]


---

.center[
![:scale 100%](img/end.gif)
]



  </textarea>
  <script src="js/vendor/remark.min.js"></script>
  <script src="js/vendor/jquery-3.2.1.min.js"></script>
  <script src="js/terminal.language.js"></script>
  <script src="js/common.js"></script>
  </body>
</html>

# vim: filetype=markdown syntax=markdown tabstop=2 shiftwidth=2 expandtab
